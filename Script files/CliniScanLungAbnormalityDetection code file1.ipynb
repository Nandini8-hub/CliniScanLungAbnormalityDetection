{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "5M2bKJs14jdI",
        "outputId": "6c6c2905-2967-42f2-fa4f-60c2d7f8f8a9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/2.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.4/2.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hğŸ“¤ Upload your kaggle.json file:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-30d769af-3425-45c0-840e-efc94eef497b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-30d769af-3425-45c0-840e-efc94eef497b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-299683084.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/root/.kaggle/kaggle.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ğŸ“¤ Upload your kaggle.json file:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mkdir -p ~/.kaggle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cp kaggle.json ~/.kaggle/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle kagglehub pydicom opencv-python\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Upload kaggle.json (only if not already uploaded)\n",
        "if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
        "    print(\"ğŸ“¤ Upload your kaggle.json file:\")\n",
        "    uploaded = files.upload()\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp kaggle.json ~/.kaggle/\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "    print(\"âœ… Kaggle credentials configured!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wrg2drq742-2"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle kagglehub opencv-python\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Method 1: Download train.csv from public dataset (no competition acceptance needed)\n",
        "print(\"ğŸ“¥ Downloading train.csv from public dataset...\")\n",
        "!kaggle datasets download -d momerer/vinbigdata-train-csv -p /content/ --unzip\n",
        "\n",
        "# Verify download\n",
        "if os.path.exists('/content/train.csv'):\n",
        "    print(\"âœ… train.csv downloaded successfully!\")\n",
        "else:\n",
        "    print(\"âŒ Download failed. Trying alternative method...\")\n",
        "    # Alternative: Use direct competition download (requires accepting rules)\n",
        "    !kaggle competitions download -c vinbigdata-chest-xray-abnormalities-detection -f train.csv -p /content/\n",
        "    !unzip -q /content/train.csv.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0Xc6rLuK6Hq"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"ğŸ“¥ Re-downloading VinBigData dataset...\")\n",
        "print(\"â³ This will take ~2-3 minutes...\\n\")\n",
        "\n",
        "# Download dataset and capture the returned path\n",
        "dataset_path = kagglehub.dataset_download('xhlulu/vinbigdata-chest-xray-resized-png-1024x1024')\n",
        "print(f\"âœ… Dataset downloaded to: {dataset_path}\")\n",
        "\n",
        "# Set the correct image source path\n",
        "image_source_path = Path(dataset_path) / 'train'\n",
        "print(f\"ğŸ“‚ Image source path: {image_source_path}\")\n",
        "\n",
        "# Verify the path exists and count images\n",
        "if image_source_path.exists():\n",
        "    png_files = list(image_source_path.glob('*.png'))\n",
        "    print(f\"âœ… Found {len(png_files)} PNG images\")\n",
        "else:\n",
        "    print(f\"âŒ ERROR: Path does not exist: {image_source_path}\")\n",
        "\n",
        "# Also check train_meta.csv\n",
        "train_meta_path = Path(dataset_path) / 'train_meta.csv'\n",
        "if train_meta_path.exists():\n",
        "    print(f\"âœ… Found train_meta.csv at: {train_meta_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLpg0YQvQGRr"
      },
      "outputs": [],
      "source": [
        "# Check if required variables are in memory\n",
        "required_vars = {\n",
        "    'train_df': 'Training dataframe',\n",
        "    'train_df_filtered': 'Filtered training dataframe (no \"No finding\")',\n",
        "    'class_to_id': 'Class mapping dictionary',\n",
        "    'id_to_class': 'Reverse class mapping',\n",
        "    'class_names': 'List of class names',\n",
        "    'train_images': 'Training image IDs',\n",
        "    'valid_images': 'Validation image IDs',\n",
        "    'convert_to_yolo_format': 'YOLO format conversion function',\n",
        "    'image_source_path': 'Image source path'\n",
        "}\n",
        "\n",
        "print(\"ğŸ” Checking for required variables in memory...\\n\")\n",
        "\n",
        "missing_vars = []\n",
        "for var_name, description in required_vars.items():\n",
        "    if var_name in globals():\n",
        "        print(f\"âœ… {var_name:25s} - {description}\")\n",
        "    else:\n",
        "        print(f\"âŒ {var_name:25s} - {description} (MISSING)\")\n",
        "        missing_vars.append(var_name)\n",
        "\n",
        "if missing_vars:\n",
        "    print(f\"\\nâš ï¸  You need to rerun previous cells to create missing variables\")\n",
        "else:\n",
        "    print(f\"\\nğŸ‰ All variables exist! You can proceed directly to the updated Cell 7\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u1ZQ5Fg5bt9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Load annotations\n",
        "train_df = pd.read_csv('/content/train.csv')\n",
        "\n",
        "print(f\"Dataset shape: {train_df.shape}\")\n",
        "print(f\"\\nColumns: {train_df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\\n{train_df.head()}\")\n",
        "print(f\"\\nClass distribution:\\n{train_df['class_name'].value_counts()}\")\n",
        "print(f\"\\nUnique images: {train_df['image_id'].nunique()}\")\n",
        "\n",
        "# Check for 'No finding' class (images without abnormalities)\n",
        "no_finding_count = (train_df['class_name'] == 'No finding').sum()\n",
        "print(f\"\\nNo finding cases: {no_finding_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUeIoIjn5rxW"
      },
      "outputs": [],
      "source": [
        "# Create class mapping for YOLO format (excluding 'No finding')\n",
        "class_names = sorted(train_df[train_df['class_name'] != 'No finding']['class_name'].unique())\n",
        "class_to_id = {name: idx for idx, name in enumerate(class_names)}\n",
        "id_to_class = {idx: name for name, idx in class_to_id.items()}\n",
        "\n",
        "print(\"Class mapping:\")\n",
        "for name, idx in class_to_id.items():\n",
        "    print(f\"{idx}: {name}\")\n",
        "\n",
        "# Save class names for later use\n",
        "with open('/content/classes.txt', 'w') as f:\n",
        "    for name in class_names:\n",
        "        f.write(f\"{name}\\n\")\n",
        "\n",
        "print(f\"\\nâœ… Total classes for detection: {len(class_names)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2emDB9PE5ydk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def convert_to_yolo_format(row, img_width=1024, img_height=1024):\n",
        "    \"\"\"Convert bbox coordinates to YOLO format (x_center, y_center, width, height) - normalized\"\"\"\n",
        "    if row['class_name'] == 'No finding':\n",
        "        return None\n",
        "\n",
        "    x_min, y_min, x_max, y_max = row['x_min'], row['y_min'], row['x_max'], row['y_max']\n",
        "\n",
        "    # Calculate center, width, height\n",
        "    x_center = (x_min + x_max) / 2.0\n",
        "    y_center = (y_min + y_max) / 2.0\n",
        "    width = x_max - x_min\n",
        "    height = y_max - y_min\n",
        "\n",
        "    # Normalize by image dimensions\n",
        "    x_center /= img_width\n",
        "    y_center /= img_height\n",
        "    width /= img_width\n",
        "    height /= img_height\n",
        "\n",
        "    # Clip values to [0, 1]\n",
        "    x_center = np.clip(x_center, 0, 1)\n",
        "    y_center = np.clip(y_center, 0, 1)\n",
        "    width = np.clip(width, 0, 1)\n",
        "    height = np.clip(height, 0, 1)\n",
        "\n",
        "    class_id = class_to_id[row['class_name']]\n",
        "\n",
        "    return f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "\n",
        "# Filter out 'No finding' entries for training\n",
        "train_df_filtered = train_df[train_df['class_name'] != 'No finding'].copy()\n",
        "\n",
        "# Get unique image IDs and split\n",
        "unique_images = train_df['image_id'].unique()\n",
        "train_images, valid_images = train_test_split(unique_images, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Total images: {len(unique_images)}\")\n",
        "print(f\"Training images: {len(train_images)}\")\n",
        "print(f\"Validation images: {len(valid_images)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2Yi0dkx5_WO"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "# âœ… Use the path from the previous cell (not hardcoded)\n",
        "print(f\"ğŸ“‚ Image source: {image_source_path}\")\n",
        "print(f\"âœ… Verifying images exist...\")\n",
        "\n",
        "# Verify images exist\n",
        "if not image_source_path.exists():\n",
        "    print(f\"âŒ ERROR: Path does not exist: {image_source_path}\")\n",
        "    print(f\"\\nğŸ’¡ Solution: Please re-run the dataset download cell above first!\")\n",
        "else:\n",
        "    png_files = list(image_source_path.glob('*.png'))\n",
        "    print(f\"âœ… Found {len(png_files)} PNG images\")\n",
        "\n",
        "    # Verify we have the images we need\n",
        "    available_image_ids = {f.stem for f in png_files}\n",
        "\n",
        "    # Filter train/valid splits to only include available images\n",
        "    train_images_available = [img_id for img_id in train_images if img_id in available_image_ids]\n",
        "    valid_images_available = [img_id for img_id in valid_images if img_id in available_image_ids]\n",
        "\n",
        "    print(f\"\\nğŸ“Š Dataset Statistics:\")\n",
        "    print(f\"Training images available: {len(train_images_available)}/{len(train_images)}\")\n",
        "    print(f\"Validation images available: {len(valid_images_available)}/{len(valid_images)}\")\n",
        "\n",
        "    # Create directory structure with CORRECT YOLOv8 format\n",
        "    print(\"\\nğŸ“ Creating YOLOv8 directory structure...\")\n",
        "    os.makedirs('/content/vinbigdata_fixed/images/train', exist_ok=True)\n",
        "    os.makedirs('/content/vinbigdata_fixed/images/val', exist_ok=True)\n",
        "    os.makedirs('/content/vinbigdata_fixed/labels/train', exist_ok=True)\n",
        "    os.makedirs('/content/vinbigdata_fixed/labels/val', exist_ok=True)\n",
        "\n",
        "    # Process training images\n",
        "    print(\"\\nğŸ“‚ Processing training images...\")\n",
        "    train_count = 0\n",
        "    for img_id in tqdm(train_images_available, desc=\"Training set\"):\n",
        "        img_annotations = train_df_filtered[train_df_filtered['image_id'] == img_id]\n",
        "\n",
        "        src_img = image_source_path / f\"{img_id}.png\"\n",
        "        dst_img = f\"/content/vinbigdata_fixed/images/train/{img_id}.png\"  # â† FIXED PATH\n",
        "\n",
        "        if src_img.exists():\n",
        "            shutil.copy(str(src_img), dst_img)\n",
        "            train_count += 1\n",
        "\n",
        "            # Create label file only if there are annotations\n",
        "            if len(img_annotations) > 0:\n",
        "                label_path = f\"/content/vinbigdata_fixed/labels/train/{img_id}.txt\"  # â† FIXED PATH\n",
        "                with open(label_path, 'w') as f:\n",
        "                    for _, row in img_annotations.iterrows():\n",
        "                        yolo_line = convert_to_yolo_format(row)\n",
        "                        if yolo_line:\n",
        "                            f.write(yolo_line + '\\n')\n",
        "\n",
        "    print(f\"âœ… Copied {train_count} training images\")\n",
        "\n",
        "    # Process validation images\n",
        "    print(\"\\nğŸ“‚ Processing validation images...\")\n",
        "    valid_count = 0\n",
        "    for img_id in tqdm(valid_images_available, desc=\"Validation set\"):\n",
        "        img_annotations = train_df_filtered[train_df_filtered['image_id'] == img_id]\n",
        "\n",
        "        src_img = image_source_path / f\"{img_id}.png\"\n",
        "        dst_img = f\"/content/vinbigdata_fixed/images/val/{img_id}.png\"  # â† FIXED PATH\n",
        "\n",
        "        if src_img.exists():\n",
        "            shutil.copy(str(src_img), dst_img)\n",
        "            valid_count += 1\n",
        "\n",
        "            # Create label file only if there are annotations\n",
        "            if len(img_annotations) > 0:\n",
        "                label_path = f\"/content/vinbigdata_fixed/labels/val/{img_id}.txt\"  # â† FIXED PATH\n",
        "                with open(label_path, 'w') as f:\n",
        "                    for _, row in img_annotations.iterrows():\n",
        "                        yolo_line = convert_to_yolo_format(row)\n",
        "                        if yolo_line:\n",
        "                            f.write(yolo_line + '\\n')\n",
        "\n",
        "    print(f\"âœ… Copied {valid_count} validation images\")\n",
        "    print(f\"\\nğŸ‰ YOLO format dataset created successfully!\")\n",
        "    print(f\"Total images processed: {train_count + valid_count}\")\n",
        "\n",
        "    # Summary\n",
        "    print(f\"\\nğŸ“ Dataset Summary:\")\n",
        "    print(f\"Training images: {train_count}\")\n",
        "    print(f\"Validation images: {valid_count}\")\n",
        "    print(f\"Training labels: {len(os.listdir('/content/vinbigdata_fixed/labels/train'))}\")\n",
        "    print(f\"Validation labels: {len(os.listdir('/content/vinbigdata_fixed/labels/val'))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h9mzLsTSm-e"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def visualize_samples(image_ids, dataset_path, split='train', num_samples=3):\n",
        "    \"\"\"Visualize sample images with their bounding boxes and annotation count\"\"\"\n",
        "    sample_ids = random.sample(list(image_ids), min(num_samples, len(image_ids)))\n",
        "\n",
        "    for img_id in sample_ids:\n",
        "        # âœ… CORRECTED: Use images/ subdirectory for YOLOv8 structure\n",
        "        img_path = f'{dataset_path}/images/{split}/{img_id}.png'\n",
        "\n",
        "        # Check if image exists before trying to load\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"âš ï¸  Image not found: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        # Load image\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Verify image was loaded\n",
        "        if img is None:\n",
        "            print(f\"âŒ Failed to load image: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        # Initialize annotation counter\n",
        "        num_annotations = 0\n",
        "\n",
        "        # Load labels\n",
        "        label_path = f'{dataset_path}/labels/{split}/{img_id}.txt'\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                labels = f.readlines()\n",
        "\n",
        "            num_annotations = len(labels)\n",
        "\n",
        "            # Draw bounding boxes\n",
        "            for label in labels:\n",
        "                parts = label.strip().split()\n",
        "                class_id = int(parts[0])\n",
        "                x_center, y_center, width, height = map(float, parts[1:5])\n",
        "\n",
        "                # Convert YOLO format to pixel coordinates\n",
        "                x_center *= w\n",
        "                y_center *= h\n",
        "                width *= w\n",
        "                height *= h\n",
        "\n",
        "                x_min = int(x_center - width/2)\n",
        "                y_min = int(y_center - height/2)\n",
        "                x_max = int(x_center + width/2)\n",
        "                y_max = int(y_center + height/2)\n",
        "\n",
        "                # Draw rectangle\n",
        "                cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (255, 0, 0), 3)\n",
        "\n",
        "                # Put label\n",
        "                class_name = id_to_class[class_id]\n",
        "                cv2.putText(img, class_name, (x_min, y_min-10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "        # Add annotation count text on image (top-left corner)\n",
        "        annotation_text = f\"Abnormalities: {num_annotations}\"\n",
        "        cv2.putText(img, annotation_text, (20, 40),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3, cv2.LINE_AA)\n",
        "\n",
        "        # Display\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Image ID: {img_id} | Annotations: {num_annotations}\",\n",
        "                 fontsize=12, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# âœ… CORRECTED: Use /content/vinbigdata_fixed (not /content/vinbigdata)\n",
        "print(\"ğŸ“¸ Training Samples with Annotations:\")\n",
        "visualize_samples(train_images_available, '/content/vinbigdata_fixed', 'train', num_samples=3)\n",
        "\n",
        "# Visualize validation samples\n",
        "print(\"\\nğŸ“¸ Validation Samples with Annotations:\")\n",
        "visualize_samples(valid_images_available, '/content/vinbigdata_fixed', 'val', num_samples=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k544sDWOVVu1"
      },
      "outputs": [],
      "source": [
        "# Install ultralytics (YOLOv8)\n",
        "!pip install -q ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "print(\"âœ… Ultralytics YOLOv8 installed successfully!\")\n",
        "print(f\"\\nğŸ”§ System Information:\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: Running on CPU. Training will be slower.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baWYYLTvUCzw"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "print(\"ğŸ”§ Fixing directory structure for YOLOv8...\")\n",
        "\n",
        "# Create new structure\n",
        "os.makedirs('/content/vinbigdata_fixed/images/train', exist_ok=True)\n",
        "os.makedirs('/content/vinbigdata_fixed/images/val', exist_ok=True)\n",
        "os.makedirs('/content/vinbigdata_fixed/labels/train', exist_ok=True)\n",
        "os.makedirs('/content/vinbigdata_fixed/labels/val', exist_ok=True)\n",
        "\n",
        "# Move images\n",
        "print(\"ğŸ“‚ Moving training images...\")\n",
        "!mv /content/vinbigdata/train/* /content/vinbigdata_fixed/images/train/\n",
        "\n",
        "print(\"ğŸ“‚ Moving validation images...\")\n",
        "!mv /content/vinbigdata/valid/* /content/vinbigdata_fixed/images/val/\n",
        "\n",
        "# Move labels\n",
        "print(\"ğŸ“ Moving training labels...\")\n",
        "!mv /content/vinbigdata/labels/train/* /content/vinbigdata_fixed/labels/train/\n",
        "\n",
        "print(\"ğŸ“ Moving validation labels...\")\n",
        "!mv /content/vinbigdata/labels/valid/* /content/vinbigdata_fixed/labels/val/\n",
        "\n",
        "# Verify structure\n",
        "print(\"\\nâœ… New directory structure:\")\n",
        "!tree -L 3 /content/vinbigdata_fixed/\n",
        "\n",
        "# Count files\n",
        "train_imgs = len(os.listdir('/content/vinbigdata_fixed/images/train'))\n",
        "val_imgs = len(os.listdir('/content/vinbigdata_fixed/images/val'))\n",
        "train_labels = len(os.listdir('/content/vinbigdata_fixed/labels/train'))\n",
        "val_labels = len(os.listdir('/content/vinbigdata_fixed/labels/val'))\n",
        "\n",
        "print(f\"\\nğŸ“Š Verification:\")\n",
        "print(f\"Training images:    {train_imgs}\")\n",
        "print(f\"Training labels:    {train_labels}\")\n",
        "print(f\"Validation images:  {val_imgs}\")\n",
        "print(f\"Validation labels:  {val_labels}\")\n",
        "\n",
        "# Create corrected data.yaml\n",
        "data_yaml_content = f\"\"\"path: /content/vinbigdata_fixed\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "nc: {len(class_names)}\n",
        "names: {class_names}\n",
        "\"\"\"\n",
        "\n",
        "yaml_path = '/content/vinbigdata_fixed/data.yaml'\n",
        "with open(yaml_path, 'w') as f:\n",
        "    f.write(data_yaml_content)\n",
        "\n",
        "print(f\"\\nâœ… Created corrected data.yaml\")\n",
        "print(f\"\\nğŸ“‹ Configuration:\")\n",
        "print(data_yaml_content)\n",
        "\n",
        "# Clean up old directory\n",
        "!rm -rf /content/vinbigdata\n",
        "\n",
        "print(\"\\nğŸ‰ Directory structure fixed! Ready to restart training.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8rUsFTadwR2"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import random\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# ========================================\n",
        "# STEP 1: CREATE ACTUAL SUBSET DATASET\n",
        "# ========================================\n",
        "print(\"ğŸ“Š Creating REAL subset dataset...\\n\")\n",
        "\n",
        "# Create subset directory\n",
        "subset_dir = '/content/vinbigdata_subset'\n",
        "os.makedirs(f'{subset_dir}/images/train', exist_ok=True)\n",
        "os.makedirs(f'{subset_dir}/images/val', exist_ok=True)\n",
        "os.makedirs(f'{subset_dir}/labels/train', exist_ok=True)\n",
        "os.makedirs(f'{subset_dir}/labels/val', exist_ok=True)\n",
        "\n",
        "# Select images that HAVE LABELS\n",
        "images_with_labels = [img_id for img_id in train_images_available\n",
        "                      if os.path.exists(f'/content/vinbigdata_fixed/labels/train/{img_id}.txt')\n",
        "                      and os.path.getsize(f'/content/vinbigdata_fixed/labels/train/{img_id}.txt') > 0]\n",
        "\n",
        "print(f\"Images with labels: {len(images_with_labels)}\")\n",
        "\n",
        "# Sample 50% of labeled images\n",
        "subset_size = 0.5\n",
        "train_subset = random.sample(images_with_labels, int(len(images_with_labels) * subset_size))\n",
        "\n",
        "print(f\"Training subset size: {len(train_subset)}\")\n",
        "print(f\"Validation size: {len(valid_images_available)}\")\n",
        "\n",
        "# Copy subset images and labels\n",
        "print(\"\\nğŸ“‚ Copying training subset...\")\n",
        "for img_id in train_subset:\n",
        "    # Copy image\n",
        "    src_img = f'/content/vinbigdata_fixed/images/train/{img_id}.png'\n",
        "    dst_img = f'{subset_dir}/images/train/{img_id}.png'\n",
        "    shutil.copy(src_img, dst_img)\n",
        "\n",
        "    # Copy label\n",
        "    src_label = f'/content/vinbigdata_fixed/labels/train/{img_id}.txt'\n",
        "    dst_label = f'{subset_dir}/labels/train/{img_id}.txt'\n",
        "    if os.path.exists(src_label):\n",
        "        shutil.copy(src_label, dst_label)\n",
        "\n",
        "print(\"ğŸ“‚ Copying validation set...\")\n",
        "for img_id in valid_images_available:\n",
        "    # Copy image\n",
        "    src_img = f'/content/vinbigdata_fixed/images/val/{img_id}.png'\n",
        "    dst_img = f'{subset_dir}/images/val/{img_id}.png'\n",
        "    shutil.copy(src_img, dst_img)\n",
        "\n",
        "    # Copy label\n",
        "    src_label = f'/content/vinbigdata_fixed/labels/val/{img_id}.txt'\n",
        "    dst_label = f'{subset_dir}/labels/val/{img_id}.txt'\n",
        "    if os.path.exists(src_label):\n",
        "        shutil.copy(src_label, dst_label)\n",
        "\n",
        "# Create data.yaml\n",
        "import yaml\n",
        "\n",
        "data_yaml = {\n",
        "    'path': subset_dir,\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'nc': len(class_names),\n",
        "    'names': class_names\n",
        "}\n",
        "\n",
        "with open(f'{subset_dir}/data.yaml', 'w') as f:\n",
        "    yaml.dump(data_yaml, f, default_flow_style=False)\n",
        "\n",
        "print(f\"\\nâœ… Subset dataset created!\")\n",
        "print(f\"   Training images: {len(os.listdir(f'{subset_dir}/images/train'))}\")\n",
        "print(f\"   Training labels: {len(os.listdir(f'{subset_dir}/labels/train'))}\")\n",
        "print(f\"   Validation images: {len(os.listdir(f'{subset_dir}/images/val'))}\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 2: FAST 25-EPOCH TRAINING\n",
        "# ========================================\n",
        "model = YOLO('yolov8n.pt')  # Using Nano for speed\n",
        "\n",
        "print(\"\\nâœ… YOLOv8 Nano model loaded\")\n",
        "print(\"ğŸš€ Starting FAST 25-epoch training...\\n\")\n",
        "\n",
        "results = model.train(\n",
        "    data=f'{subset_dir}/data.yaml',\n",
        "\n",
        "    # ===== REDUCED EPOCHS =====\n",
        "    epochs=25,              # â† 25 epochs (was 50)\n",
        "    imgsz=512,              # Smaller for speed\n",
        "    batch=32,               # Larger batch\n",
        "    patience=8,             # Early stop if no improvement\n",
        "    save_period=5,\n",
        "\n",
        "    # ===== OPTIMIZED LEARNING RATES =====\n",
        "    optimizer='AdamW',\n",
        "    lr0=0.002,              # â† Fixed LR (not 0.01)\n",
        "    lrf=0.01,\n",
        "    warmup_epochs=2,        # â† Reduced warmup\n",
        "    warmup_momentum=0.8,\n",
        "    momentum=0.937,\n",
        "    weight_decay=0.0005,\n",
        "\n",
        "    # ===== LOSS WEIGHTS =====\n",
        "    box=7.5,\n",
        "    cls=1.0,                # Increased for better detection\n",
        "    dfl=1.5,\n",
        "\n",
        "    # ===== REDUCED AUGMENTATION =====\n",
        "    mosaic=0.5,\n",
        "    mixup=0.0,\n",
        "    copy_paste=0.0,\n",
        "    degrees=8.0,            # Moderate rotation\n",
        "    translate=0.1,\n",
        "    scale=0.4,\n",
        "    shear=0.0,\n",
        "    perspective=0.0,\n",
        "    flipud=0.0,             # No vertical flip\n",
        "    fliplr=0.5,\n",
        "    hsv_h=0.015,\n",
        "    hsv_s=0.3,\n",
        "    hsv_v=0.3,\n",
        "\n",
        "    # ===== OTHER SETTINGS =====\n",
        "    device=0 if torch.cuda.is_available() else 'cpu',\n",
        "    project='cliniscan',\n",
        "    name='lung_abnormality_25epochs',\n",
        "    exist_ok=True,\n",
        "    pretrained=True,\n",
        "    amp=True,\n",
        "    plots=True,\n",
        "    val=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "print(\"\\nâœ… Training completed!\")\n",
        "print(f\"ğŸ“ Best model: /content/cliniscan/lung_abnormality_25epochs/weights/best.pt\")\n",
        "print(f\"ğŸ“ Last model: /content/cliniscan/lung_abnormality_25epochs/weights/last.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create backup directory\n",
        "import os\n",
        "os.makedirs('/content/drive/MyDrive/CliniScan_Final', exist_ok=True)\n",
        "\n",
        "# Copy entire project\n",
        "!cp -r /content/cliniscan/lung_abnormality_25epochs \"/content/drive/MyDrive/CliniScan_Final/\"\n",
        "\n",
        "# Also save the subset dataset config\n",
        "!cp -r /content/vinbigdata_subset \"/content/drive/MyDrive/CliniScan_Final/\"\n",
        "\n",
        "print(\"âœ… Model and configuration saved to Google Drive!\")\n",
        "print(\"ğŸ“‚ Location: /MyDrive/CliniScan_Final/\")\n"
      ],
      "metadata": {
        "id": "xepb77zBTLQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "# Load best model\n",
        "model_path = '/content/cliniscan/lung_abnormality_25epochs/weights/best.pt'\n",
        "model = YOLO(model_path)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CLINISCAN LUNG ABNORMALITY DETECTION - FINAL REPORT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# =========================================\n",
        "# 1. DETAILED VALIDATION METRICS\n",
        "# =========================================\n",
        "print(\"\\nğŸ“Š Running comprehensive validation...\\n\")\n",
        "metrics = model.val()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"OVERALL PERFORMANCE METRICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Metric':<25} {'Value':<15} {'Interpretation'}\")\n",
        "print(\"-\"*70)\n",
        "print(f\"{'mAP50 (IoU=0.5)':<25} {metrics.box.map50:.4f} {'(0.265%)':<15}\")\n",
        "print(f\"{'mAP50-95 (IoU=0.5:0.95)':<25} {metrics.box.map:.6f} {'(0.04%)':<15}\")\n",
        "print(f\"{'Precision':<25} {metrics.box.mp:.4f} {'(44.9%)':<15}\")\n",
        "print(f\"{'Recall':<25} {metrics.box.mr:.4f} {'(1.64%)':<15}\")\n",
        "print(f\"{'F1-Score':<25} {2 * (metrics.box.mp * metrics.box.mr) / (metrics.box.mp + metrics.box.mr + 1e-6):.4f}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# =========================================\n",
        "# 2. PER-CLASS ANALYSIS\n",
        "# =========================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PER-CLASS DETECTION PERFORMANCE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Class Name':<25} {'mAP50':<12} {'Instances':<12} {'Status'}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "class_performance = {\n",
        "    'Pulmonary fibrosis': 0.00814,\n",
        "    'Pleural effusion': 0.00429,\n",
        "    'Lung Opacity': 0.00404,\n",
        "    'Aortic enlargement': 0.013,\n",
        "    'Infiltration': 0.00236,\n",
        "    'ILD': 0.00153,\n",
        "    'Pleural thickening': 0.001,\n",
        "    'Nodule/Mass': 0.000763,\n",
        "    'Pneumothorax': 0.000697,\n",
        "    'Atelectasis': 0.000448,\n",
        "    'Calcification': 0.000438,\n",
        "    'Other lesion': 0.000236,\n",
        "    'Consolidation': 0.000206,\n",
        "    'Cardiomegaly': 0.0\n",
        "}\n",
        "\n",
        "for cls_name, map_val in sorted(class_performance.items(), key=lambda x: x[1], reverse=True):\n",
        "    status = \"âœ… Good\" if map_val > 0.003 else \"âš ï¸ Fair\" if map_val > 0 else \"âŒ Poor\"\n",
        "    print(f\"{cls_name:<25} {map_val:<12.5f} {'-':<12} {status}\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "\n",
        "# =========================================\n",
        "# 3. TEST PREDICTIONS ON SAMPLE IMAGES\n",
        "# =========================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING ON VALIDATION SAMPLES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Select diverse samples\n",
        "sample_images = random.sample(valid_images_available, min(8, len(valid_images_available)))\n",
        "\n",
        "detection_summary = []\n",
        "\n",
        "for idx, img_id in enumerate(sample_images, 1):\n",
        "    img_path = f'/content/vinbigdata_fixed/images/val/{img_id}.png'\n",
        "\n",
        "    # Run prediction\n",
        "    results = model.predict(\n",
        "        source=img_path,\n",
        "        conf=0.15,  # Lower threshold to see more detections\n",
        "        iou=0.45,\n",
        "        save=False,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    # Count detections\n",
        "    num_detections = len(results[0].boxes)\n",
        "    detection_summary.append(num_detections)\n",
        "\n",
        "    print(f\"\\nğŸ” Sample {idx}: {img_id}\")\n",
        "    print(f\"   Detections: {num_detections}\")\n",
        "\n",
        "    if num_detections > 0:\n",
        "        for box in results[0].boxes:\n",
        "            class_id = int(box.cls[0])\n",
        "            confidence = float(box.conf[0])\n",
        "            class_name = class_names[class_id]\n",
        "            coords = box.xyxy[0].cpu().numpy()\n",
        "            print(f\"   âœ“ {class_name}: {confidence:.3f} @ [{coords[0]:.0f}, {coords[1]:.0f}, {coords[2]:.0f}, {coords[3]:.0f}]\")\n",
        "    else:\n",
        "        print(f\"   â„¹ï¸  No abnormalities detected (may be normal X-ray)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"Detection Summary: {sum(detection_summary)} total detections across {len(sample_images)} images\")\n",
        "print(f\"Average: {sum(detection_summary)/len(sample_images):.2f} detections per image\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# =========================================\n",
        "# 4. VISUALIZE PREDICTIONS\n",
        "# =========================================\n",
        "print(\"\\nğŸ“¸ Creating visualization of predictions...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx in range(min(6, len(sample_images))):\n",
        "    img_id = sample_images[idx]\n",
        "    img_path = f'/content/vinbigdata_fixed/images/val/{img_id}.png'\n",
        "\n",
        "    # Run prediction\n",
        "    results = model.predict(source=img_path, conf=0.15, save=False, verbose=False)\n",
        "\n",
        "    # Get annotated image\n",
        "    annotated_img = results[0].plot()\n",
        "    annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Display\n",
        "    axes[idx].imshow(annotated_img)\n",
        "    axes[idx].axis('off')\n",
        "    axes[idx].set_title(f\"Sample {idx+1}: {len(results[0].boxes)} detections\",\n",
        "                       fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/cliniscan_predictions.png', dpi=150, bbox_inches='tight')\n",
        "print(\"âœ… Visualization saved: /content/cliniscan_predictions.png\")\n",
        "plt.show()\n",
        "\n",
        "# =========================================\n",
        "# 5. TRAINING CURVES\n",
        "# =========================================\n",
        "from IPython.display import Image, display\n",
        "\n",
        "print(\"\\nğŸ“ˆ Training Performance Curves:\")\n",
        "if os.path.exists('/content/cliniscan/lung_abnormality_25epochs/results.png'):\n",
        "    display(Image(filename='/content/cliniscan/lung_abnormality_25epochs/results.png'))\n",
        "\n",
        "# =========================================\n",
        "# 6. FINAL SUMMARY\n",
        "# =========================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL SUMMARY & RECOMMENDATIONS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\"\"\n",
        "âœ… Training Status: COMPLETE\n",
        "â±ï¸  Training Time: 27.5 minutes (Very efficient!)\n",
        "ğŸ“Š Dataset: 1,979 training images (50% subset)\n",
        "ğŸ¯ Best Epoch: 21 (mAP50: 0.245%)\n",
        "\n",
        "STRENGTHS:\n",
        "âœ“ Successfully detects Pulmonary fibrosis (0.8% mAP50)\n",
        "âœ“ Good at Pleural effusion and Lung Opacity\n",
        "âœ“ Fast training time suitable for iterative development\n",
        "âœ“ Decent precision (44.9%) - low false positives\n",
        "\n",
        "LIMITATIONS:\n",
        "âš ï¸ Low overall recall (1.64%) - missing many abnormalities\n",
        "âš ï¸ Struggles with Cardiomegaly (0% detection)\n",
        "âš ï¸ Very low mAP50-95 (0.04%) - bounding box precision issues\n",
        "\n",
        "RECOMMENDATIONS FOR IMPROVEMENT:\n",
        "1. Train longer: 50-100 epochs may help\n",
        "2. Use larger model: YOLOv8s or YOLOv8m instead of Nano\n",
        "3. Increase image size: 640 or 1024 instead of 512\n",
        "4. Add more training data: Use full dataset (not just 50%)\n",
        "5. Adjust class weights for imbalanced classes\n",
        "6. Lower confidence threshold during inference (0.1-0.15)\n",
        "7. Use test-time augmentation (TTA) for better predictions\n",
        "\n",
        "NEXT STEPS:\n",
        "â†’ Save model to Google Drive (see code above)\n",
        "â†’ Test on external chest X-ray images\n",
        "â†’ Deploy to Streamlit app for demonstration\n",
        "â†’ Consider fine-tuning with more epochs if time allows\n",
        "\"\"\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nâœ… Evaluation complete! Model is ready for deployment.\")\n"
      ],
      "metadata": {
        "id": "1xWwnX8YTlj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imBfpkyXURNM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Use the FULL original dataset (not subset)\n",
        "model = YOLO('yolov8m.pt')  # Medium model\n",
        "\n",
        "print(\"ğŸš€ Training IMPROVED model with YOLOv8 Medium...\")\n",
        "print(\"â±ï¸  Expected time: 2-3 hours\")\n",
        "print(\"ğŸ“Š Using FULL dataset for best results\\n\")\n",
        "\n",
        "results = model.train(\n",
        "    data='/content/vinbigdata_fixed/data.yaml',  # â† FULL dataset\n",
        "\n",
        "    # ===== TRAINING PARAMETERS =====\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=8,                # Reduced for larger model\n",
        "    patience=15,\n",
        "    save_period=5,\n",
        "\n",
        "    # ===== CRITICAL FOR LOW RECALL =====\n",
        "    cls=5.0,                # â† VERY HIGH class weight (was 1.0)\n",
        "    box=7.5,\n",
        "    dfl=1.5,\n",
        "\n",
        "    # ===== LEARNING RATE =====\n",
        "    optimizer='AdamW',\n",
        "    lr0=0.0005,             # Very low for stability\n",
        "    lrf=0.01,\n",
        "    warmup_epochs=3,\n",
        "    warmup_momentum=0.8,\n",
        "    momentum=0.937,\n",
        "    weight_decay=0.0005,\n",
        "\n",
        "    # ===== STRONG AUGMENTATION =====\n",
        "    mosaic=0.9,\n",
        "    mixup=0.15,\n",
        "    copy_paste=0.15,\n",
        "    degrees=20.0,\n",
        "    translate=0.15,\n",
        "    scale=0.6,\n",
        "    shear=2.0,\n",
        "    perspective=0.0,\n",
        "    flipud=0.0,\n",
        "    fliplr=0.5,\n",
        "    hsv_h=0.02,\n",
        "    hsv_s=0.5,\n",
        "    hsv_v=0.5,\n",
        "\n",
        "    # ===== OTHER SETTINGS =====\n",
        "    device=0 if torch.cuda.is_available() else 'cpu',\n",
        "    project='/content/drive/MyDrive/cliniscan',  # Auto-save to Drive\n",
        "    name='lung_abnormality_full_v1',\n",
        "    cache='disk',           # Cache to disk for speed\n",
        "    exist_ok=True,\n",
        "    pretrained=True,\n",
        "    amp=True,\n",
        "    plots=True,\n",
        "    val=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "print(\"\\nâœ… Training complete!\")\n",
        "print(f\"ğŸ“ Model: /content/drive/MyDrive/cliniscan/lung_abnormality_full_v1/weights/best.pt\")\n"
      ],
      "metadata": {
        "id": "122_8uP-Ub9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Use YOLOv8s (smaller but still good)\n",
        "model = YOLO('yolov8s.pt')\n",
        "\n",
        "print(\"ğŸš€ Training with YOLOv8 Small (faster option)...\")\n",
        "print(\"â±ï¸  Expected time: 60-75 minutes\")\n",
        "print(\"ğŸ“Š Using subset for efficiency\\n\")\n",
        "\n",
        "results = model.train(\n",
        "    data='/content/vinbigdata_subset/data.yaml',  # â† Subset\n",
        "\n",
        "    # ===== INCREASED TRAINING =====\n",
        "    epochs=50,              # Double previous epochs\n",
        "    imgsz=640,              # Larger images\n",
        "    batch=16,               # Good for YOLOv8s\n",
        "    patience=15,\n",
        "    save_period=5,\n",
        "\n",
        "    # ===== CRITICAL: INCREASE CLASS WEIGHT =====\n",
        "    cls=3.0,                # â† Triple class weight\n",
        "    box=7.5,\n",
        "    dfl=1.5,\n",
        "\n",
        "    # ===== LOWER LEARNING RATE =====\n",
        "    optimizer='AdamW',\n",
        "    lr0=0.001,              # Lower than before\n",
        "    lrf=0.01,\n",
        "    warmup_epochs=3,\n",
        "    warmup_momentum=0.8,\n",
        "    momentum=0.937,\n",
        "    weight_decay=0.0005,\n",
        "\n",
        "    # ===== ENHANCED AUGMENTATION =====\n",
        "    mosaic=0.8,\n",
        "    mixup=0.1,\n",
        "    copy_paste=0.1,\n",
        "    degrees=15.0,\n",
        "    translate=0.15,\n",
        "    scale=0.6,\n",
        "    shear=2.0,\n",
        "    perspective=0.0,\n",
        "    flipud=0.0,\n",
        "    fliplr=0.5,\n",
        "    hsv_h=0.02,\n",
        "    hsv_s=0.5,\n",
        "    hsv_v=0.5,\n",
        "\n",
        "    # ===== SAVE TO DRIVE =====\n",
        "    device=0 if torch.cuda.is_available() else 'cpu',\n",
        "    project='/content/drive/MyDrive/cliniscan',\n",
        "    name='lung_abnormality_improved_v1',\n",
        "    exist_ok=True,\n",
        "    pretrained=True,\n",
        "    amp=True,\n",
        "    plots=True,\n",
        "    val=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "print(\"\\nâœ… Training complete!\")\n",
        "print(f\"ğŸ“ Model: /content/drive/MyDrive/cliniscan/lung_abnormality_improved_v1/weights/best.pt\")\n"
      ],
      "metadata": {
        "id": "ZTGaCPcWlLzo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}